# (PART) Statistical Inference {-} 

# Confidence Intervals {#CIs}

```{r setup-CIs, include=FALSE, purl=FALSE}
chap <- 10
lc <- 0
rq <- 0
# **`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`**
# **`r paste0("(RQ", chap, ".", (rq <- rq + 1), ")")`**

knitr::opts_chunk$set(
  tidy = FALSE, 
  out.width = '\\textwidth', 
  fig.height = 4,
  fig.align='center',
  warning = FALSE
  )

options(scipen = 99, digits = 3)

# Set random number generator see value for replicable pseudorandomness. Why 76?
# https://www.youtube.com/watch?v=xjJ7FheCkCU
set.seed(2018)
```

In Chapter \@ref(sampling), we developed a theory of repeated samples. But what does this mean for your data analysis? If you only have one sample in front of you, how are you supposed to understand properties of the sampling distribution and your estimators? In this chapter we tackle these questions based upon formulas provided to us via mathematical theory. 

### Needed Packages {-}

Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). If needed, read Section \@ref(packages) for information on how to install and load R packages.

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(moderndive)
library(infer)
library(janitor)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
# Packages needed internally, but not in text.
library(readr)
library(knitr)
library(kableExtra)
```

## Theory based upon assumptions and models {#theory-two}

In the table below, we provide some basic properties of common sampling statistics you are likely to encounter in this course. (How do we know these properties are true? These have been proven mathematically by statisticians.)

```{r SE-table, echo=FALSE, message=FALSE}
if(!file.exists("rds/ch10_SE_table.rds")){
  ch10_SE_table <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQXpL0Gv4FJDpLdvfVOyyoUiwPzBxgzApeBrl9GGYOSRg6jBIGdonQFHvdQQl3lMFQQR3PAmxx7y6FQ/pub?gid=164147569&single=true&output=csv" %>% 
    read_csv(na = "")
    write_rds(ch10_SE_table, "rds/ch10_SE_table.rds")
} else {
  ch10_SE_table <- read_rds("rds/ch10_SE_table.rds")
}

ch10_SE_table %>% 
  kable(
    caption = "Properties of Sample Statistics", 
    booktabs = TRUE,
    escape = FALSE
  ) %>% 
  kable_styling(font_size = ifelse(knitr:::is_latex_output(), 10, 16),
                latex_options = c("HOLD_position")) %>%
  column_spec(1, width = "0.5in") %>% 
  column_spec(2, width = "0.7in") %>%
  column_spec(3, width = "1in") %>%
  column_spec(4, width = "1.1in") %>% 
  column_spec(5, width = "1in")
```

As an example, let’s say you are trying to estimate the population average age at the football game $\mu$. Let's use our simulated `football_fans` dataset again that has information on the whole population of 40,000 fans.

<!-- change seed in chapter 9 to 2018 for the football fan data. This results in a better example to demonstrate CIs later on-->

```{r, echo = FALSE}
set.seed(2018)
```

```{r}
football_fans <- data.frame(home_fan = rbinom(40000, 1, 0.91),
                            age = rnorm(40000, 30, 8)) %>% 
  mutate(age = case_when(age < 0 ~ 0,
                         age >=0 ~ age))
sample_10 <- sample_n(football_fans, size = 10)
sample_10 %>% 
  summarize(mean_age = mean(age),
            var_age = var(age))
```
To estimate the average age, you take a sample of $n = 10$ participants, producing an estimate of $\bar{x} =$ `r round(mean(sample_10$age),1)` years old. Your question is simply: is this a good estimate?

* The estimator here is the sample mean, $\bar{x}$. 
* We know that the sample mean provides an unbiased estimate of the population mean. In the average possible sample, this statistic will be right.
* We know that the sampling distribution of the sample mean is the normal distribution. This is unimodal and symmetric, meaning that our estimate is just as likely larger than this population mean as it is smaller. 
* The standard error of a sample mean is $SE(\bar{x}) = s/\sqrt{n}$. In this sample, since $s^2 =$ `r round(var(sample_10$age),1)`, we can calculate this standard error to be  $SE(\bar{x}) =$ `r round(var(sample_10$age),1)`$/\sqrt{10} =$ `r round(sqrt(var(sample_10$age)) / sqrt(10), 2) `. Note that a standard error is always in the same units as the original variable, so in this case the standard error is `r round(sqrt(var(sample_10$age)) / sqrt(10), 2) ` *years*. Comparing this to the sample mean ($\bar{x} =$ `r round(mean(sample_10$age),1)`) this gives us a sense that we are somewhat close to the true parameter value. 

Note that we can extend the above properties to *differences* between groups as well. In general,

* $Bias(X_1 - X_2) = Bias(X_1) - Bias(X_2) \dashrightarrow$ If $X_1, X_2$ are unbiased, then $X_1 - X_2$ is also unbiased.
* So long as $X_1$ and $X_2$ are independent, $\dashrightarrow SE(X_1 – X_2) = \sqrt{[SE(X_1)]^2 + [SE(X_2)]^2}$ 
* $Dist(X_1 - X_2) \dashrightarrow$ if $X_1, X_2$ are independent, then $X_1 – X_2$ are independent.

This may seem really abstract. As an example, let’s focus on estimating the difference means between two groups in the population $(\mu_1 - \mu_2)$. In our `football_fans` example, we could consider whether there is a difference in average age between home fans and away fans, so $\mu_1$ refers here to the average age of all home fans in the population, and $\mu_2$ refers to the average age of all away fans in the population. We can estimate this difference in average age using $\bar{x}_1 - \bar{x}_2$ in our sample, where $\bar{x}_1$ is the average age of home fans in our sample and $\bar{x}_2$ is the average age of away fans in our sample. Using information in Table \@ref(tab:SE-table) above, because $\bar{x}_1$ is and unbiased estimator for $\mu_1$ and $\bar{x}_2$ is an unbiased estimator for $\mu_2$, we have: 

$$Bias(\bar{x}_1 - \bar{x}_2) = Bias(\bar{x}_1) - Bias(\bar{x}_2) = 0$$
That is, on average, $\bar{x}_1 - \bar{x}_2$ will give us an unbiased estimate of $\mu_1 - \mu_2$. Also, because the age of home fans is independent of the age of away fans, we have:

$$SE(\bar{x}_1 - \bar{x}_2) = \sqrt{[SE(\bar{x}_1)]^2 + [SE(\bar{x}_2)]^2} = \sqrt{(s_1^2/n_1 + s_2^2/n_2)}$$

$$\bar{x}_1 - \bar{x}_2 \sim N(mean = \mu_1 - \mu_2, SE = \sqrt{(s_1^2/n_1 + s_2^2/n_2)})$$
Let's demonstrate this with our `football_fans` data by drawing a random sample of $n=100$ fans and computing $\bar{x}_1 - \bar{x}_2$. 

```{r, echo = FALSE}
set.seed(2018)
```

```{r}
sample1_football_fans <- rep_sample_n(football_fans, size = 100, reps = 1)
mean_age_by_fan_type <- sample1_football_fans %>% group_by(home_fan) %>% 
  summarise(mean_age = mean(age),
            sd_age = sd(age),
            n = n(),
            SE_xbar = sd_age / sqrt(n))

mean_age_by_fan_type

diff_means <- as.numeric(mean_age_by_fan_type[1,2]) - as.numeric(mean_age_by_fan_type[2,2])

SE_diff_means <- as.numeric(sqrt(mean_age_by_fan_type[1, "SE_xbar"]^2 + mean_age_by_fan_type[2, "SE_xbar"]^2))
SE_diff_means
```

We see here that $\bar{x}_1 - \bar{x}_2 =$ `r diff_means` and $SE(\bar{x}_1 - \bar{x}_2) =$ `r SE_diff_means`. In our particular sample, home fans are older, but because the magnitude of our standard error is roughly 1.5 times the size of our point estimate, this indicates we have a relatively imprecise estimate. 

We could also look at the sampling distribution of $\bar{x}_1 - \bar{x}_2 =$ by taking 10,000 repeated samples and computing the difference in means in each.

```{r, echo = FALSE}
set.seed(2018)
```

```{r diff-means, fig.cap = "Samping distribution of difference in means"}
samples_football_fans <- rep_sample_n(football_fans, size = 100, reps = 10000)
mean_age_by_fan_type <- samples_football_fans %>% 
  group_by(home_fan, replicate) %>% 
  summarise(mean_age = mean(age)) %>% 
  spread(key = home_fan, value = mean_age) %>% 
  rename("mean_age_away_fan" = `0`, "mean_age_home_fan" = `1`) %>% 
  mutate(diff_means = mean_age_home_fan - mean_age_away_fan)

ggplot(mean_age_by_fan_type, aes(x = diff_means)) +
  geom_histogram(color = "white")

pop_mean_age_by_fan_type <- football_fans %>% 
  group_by(home_fan) %>% 
  summarise(mean_age = mean(age),
            sd_age = sd(age))
pop_mean_age_by_fan_type
```
We see that the sampling distribution of $\bar{x}_1 - \bar{x}_2$ follows a normal distribution centered around the true population mean $\mu_1 - \mu_2 =$ `r as.numeric(pop_mean_age_by_fan_type[1,2]) - as.numeric(pop_mean_age_by_fan_type[2,2])`, as expected based on the properties presented in Table \@ref(SE-table).

What does this mean for your data analysis?

* You need to think about sample size and how it might affect the sampling distribution. 
* If you have a large enough sample (e.g., $n > 50$), you can probably assume the sampling distribution is normally distributed. 
* If you have a smaller sample (e.g., $n < 50$), you should look up what the appropriate sampling distribution would be (e.g., t-distribution, F-distribution). 

Importantly, what this does not mean is that you need to get a larger sample! 

## Combining an estimate with its precision

A **confidence interval** gives a range of plausible values for a parameter. It depends on a specified confidence level with higher confidence levels corresponding to wider confidence intervals and lower confidence levels corresponding to narrower confidence intervals. Common confidence levels include 90%, 95%, and 99%.

Usually we don’t just begin sections with a definition, but *confidence intervals* are simple to define and play an important role in the sciences and any field that uses data. 
You can think of a confidence interval as playing the role of a net when fishing. Using a single point-estimate to estimate an unknown parameter is like trying to catch a fish in a murky lake with a single spear, and using a confidence interval is like fishing with a net. We can throw a spear where we saw a fish, but we will probably miss. If we toss a net in that area, we have a good chance of catching the fish. Analogously, if we report a point estimate, we probably won't hit the exact population parameter, but if we report a range of plausible values based around our statistic, we have a good shot at catching the parameter. 

<!--want to include the pic from the old slides to accompany the analogy? Also took language from the slides- need to be cited?-->

### Confidence Interval with the Normal distribution
If the sampling distribution of an estimator is normally distributed, then we can use properties of the standard normal distribution to create a confidence interval. Recall that in the standard normal distribution:

* 95% of the values are between -1.96 and +1.96. 
* 90% of values are between -1.68 and +1.68. 

<!--insert graphic of the empirical rule here?-->

Using this, we can define a 95% confidence interval for a population parameter as,
$$(Estimate \ \ – \ 1.96*SE(Estimate),\ \ \ Estimate + 1.96*SE(Estimate))$$
For example, a 95% confidence interval for the population mean $\mu$ can be constructed based upon the sample mean as, $$(\bar{x} - 1.96 * SE(\bar{x}), \ \bar{x} + 1.96*SE(\bar{x}))$$

In our penny example, our original sample `pennies_sample` had $\bar{x} =$ `r mean(pennies_sample$age_in_2011)` and $SE(\bar{x}) = \frac{s}{\sqrt{n}} =$ `r sd(pennies_sample$age_in_2011)/sqrt(40)`, which gives a confidence interval of (`r round(mean(pennies_sample$age_in_2011) - 1.96*sd(pennies_sample$age_in_2011)/sqrt(40), 2)`, `r round(mean(pennies_sample$age_in_2011) + 1.96*sd(pennies_sample$age_in_2011)/sqrt(40), 2)`). 

A few properties are worth keeping in mind:

* This interval is *symmetric*. This symmetry follows from the fact that the normal distribution is a symmetric distribution. *If the sampling distribution is not normal, the confidence interval may not be symmetric*.
* The multiplier 1.96 used in this interval corresponding to 95% comes directly from properties of the normal distribution. *If the sampling distribution is not normal, this multiplier might be different*. For example, this multiplier is *larger* when the distribution has heavy tails, as with the t-distribution. The multiplier will also be different if you want to use a level of confidence other than 95%. 

<!--either here or as a class/homework exercise, could demonstrate the empirical rule / these cutoff values via simulations-->


## Interpreting a Confidence Interval
Like many statistics, while a confidence interval is fairly straightforward to construct, it is very easy to interpret incorrectly. In fact, many researchers – statisticians included – get the interpretation of confidence intervals wrong. This goes back to the idea of **counterfactual thinking** that we introduced previously: a confidence interval is a property of a population and estimator, not a particular sample. It asks: if I constructed this interval in every possible sample, in what percentage of samples would I correctly include the true population parameter? 

To see this, let’s return to the sampling distribution of the sample mean for our age of football fans example. Recall that we have simulated population data for all 40,000 fans and we took 10,000 repeated samples of size 100. Figure \@ref(fig:samp-dist-mean) shows the sampling distribution of the sample mean. Recall that the true population mean is `r mean(football_fans$age)`

```{r samp-dist-mean, fig.cap="Sampling Distribution of Average Age of Fans at a Football Game", message = FALSE, warning = FALSE}
set.seed(2018)
samp_means_football_fans <- samples_football_fans %>% 
  group_by(replicate) %>% summarise(mean = mean(age),
                                    sd = sd(age),
                                    n = n(),
                                    se = sd / sqrt(n))

mu <- mean(football_fans$age)
samp_dist_plot <- 
  ggplot(samp_means_football_fans) +
    geom_histogram(aes(x = mean), color = "white") +
    geom_vline(xintercept = mu, color = "blue")
samp_dist_plot
```


Assume that the sample we actually observed was `replicate = 437`, which had $\bar{x} =$ `r samp_means_football_fans[437,2]`. If we used this sample mean to construct a 95% confidence interval, the population mean would be in this interval, right? Figure \@ref(fig:samp-dist-mean-2) shows a confidence interval shaded around $\bar{x} =$ `r samp_means_football_fans[437,2]`, which is indicated by the red line. This confidence interval successfully includes the true population mean. 

```{r samp-dist-mean-2, warning = FALSE, message = FALSE, fig.cap="Confidence Interval shaded for an observed sample mean of 29.8"}
xbar <- filter(samp_means_football_fans, replicate == 437)$mean
xbar
SE <- filter(samp_means_football_fans, replicate == 437)$se
endpoints <- c(xbar - 1.96*SE, xbar + 1.96*SE)
samp_dist_plot +
  shade_ci(endpoints) +
  geom_vline(xintercept = xbar, color = "red")

```

Assume now that we were unlucky and drew a sample with a mean far from the population mean. One such case is `replicate = ` `r 545`, which had $\bar{x} =$ `r samp_means_football_fans[545,2]`. In this case, is the population mean in this interval? Figure \@ref(samp-dist-mean-3) displays this scenario.

```{r samp-dist-mean-3, warning = FALSE, message = FALSE, fig.cap="Confidence Interval shaded for an observed sample mean of 32.3"}
xbar <- filter(samp_means_football_fans, replicate == 545)$mean
SE <- filter(samp_means_football_fans, replicate == 545)$se
endpoints <- c(xbar - 1.96*SE, xbar + 1.96*SE)
samp_dist_plot +
  shade_ci(endpoints) +
  geom_vline(xintercept = xbar, color = "red")

```
In this case, the confidence interval does not include the true population mean. Importantly, remember that in real life we only have the data in front of us from one sample. *We don’t know what the population mean is*, and we don’t know if our estimate is the value near to the mean (Figure \@ref(samp-dist-mean-2) ) or far from the mean (Figure \@ref(samp-dist-mean-3) ). Also recall `replicate = ` `r 545` was a legitimate random sample drawn from the population of 40,000 football fans. Just by chance, it is possible to observe a sample mean that is far from the true population mean. 

We could compute 95% confidence intervals for all 10,000 of our repeated samples, and we would expect approximately 95% of them to contain the true mean. 
```{r}
mu <- mean(football_fans$age)
CIs_football_fans <- samp_means_football_fans %>% 
  mutate(lb_95 = mean - 1.96*se,
         ub_95 = mean + 1.96*se,
         captured_95 = lb_95 <= mu & mu <= ub_95)
sum(CIs_football_fans$captured_95) / 10000
```
In fact, `r round((sum(CIs_football_fans$captured_95) / 10000)*100,2)`% of the 10,000 do capture the true mean. 

For visualization purposes, we'll take a smaller subset of 100 of these confidence intervals and display the results in Figure \@ref(CI-fig). In this smaller subset, 96 of the 100 95% confidence intervals contain the true population mean. 
```{r CI-fig, fig.cap="Confidence Interval for Average Age from 100 repeated samples of size 100"}
set.seed(2018)
CI_subset <- sample_n(CIs_football_fans, 100) %>% 
  mutate(replicate_id = seq(1:100))
ggplot(CI_subset) +
  geom_point(aes(x = mean, y = replicate_id, color = captured_95)) +
  geom_segment(aes(y = replicate_id, yend = replicate_id, x = lb_95, xend = ub_95, 
                   color = captured_95)) +
  labs(
    x = expression("Age in 2011 (Years)"),
    y = "Replicate ID",
    title = expression(paste("95% percentile-based confidence intervals for ", 
                             mu, sep = ""))
  ) +
  scale_color_manual(values = c("blue", "orange")) + 
  geom_vline(xintercept = mu, color = "red") 
```

## Example: One proportion {#one-prop-ci}

Let's revisit our exercise of trying to estimate the proportion of red balls in the bowl from Chapter \@ref(sampling). We are now interested in determining a confidence interval for population parameter $\pi$, the proportion of balls that are red out of the total $N = 2400$ red and white balls. 

We will use the first sample reported from Ilyas and Yohan in Subsection \@ref(student-shovels) for our point estimate. They observed 21 red balls out of the 50 in their shovel. This data is stored in the `tactile_shovel1` data frame in the `moderndive` package.

<!-- Need to include this in the pkg! -->

```{r include=FALSE}
color <- c(rep("red", 21), rep("white", 50 - 21)) %>% 
  sample()
tactile_shovel1 <- tibble::tibble(color)
```


```{r}
tactile_shovel1
```

### Observed Statistic

To compute the proportion that are red in this data we can use the `specify() %>% calculate()` workflow. Note the use of the `success` argument here to clarify which of the two colors `"red"` or `"white"` we are interested in.

```{r}
n <- dim(tactile_shovel1)[1]

prop_red_stats <- tactile_shovel1 %>% 
  summarize(n = n(),
            pi_hat = sum(color == "red") / n,
            SE_pi_hat = sqrt(pi_hat*(1-pi_hat)/n))
prop_red_stats
```

We can compute the lower and upper limits of the confidence interval using the formula in ... 

```{r}
CI <- prop_red_stats %>% 
  summarize(lower = pi_hat - 1.96*SE_pi_hat,
            upper = pi_hat + 1.96*SE_pi_hat)
CI
```


We are 95% confident that the true proportion of red balls in the bowl is between `r CI[["lower"]]` and `r CI[["upper"]]`. This level of confidence is based on the standard error-based method including the true proportion 95% of the time if many different samples (not just the one we used) were collected and confidence intervals were created.

## Example: Comparing two proportions

If you see someone else yawn, are you more likely to yawn? In an [episode](http://www.discovery.com/tv-shows/mythbusters/mythbusters-database/yawning-contagious/) of the show *Mythbusters*, they tested the myth that yawning is contagious. The snippet from the show is available to view in the United States on the Discovery Network website [here](https://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious). More information about the episode is also available on IMDb [here](https://www.imdb.com/title/tt0768479/).

Fifty adults who thought they were being considered for an appearance on the show were interviewed by a show recruiter ("confederate") who either yawned or did not. Participants then sat by themselves in a large van and were asked to wait. While in the van, the Mythbusters watched via hidden camera to see if the unaware participants yawned. The data frame containing the results is available at `mythbusters_yawn` in the `moderndive` package. Let's check it out.

```{r}
mythbusters_yawn
```

- The participant ID is stored in the `subj` variable with values of 1 to 50.
- The `group` variable is either `"seed"` for when a confederate was trying to influence the participant or `"control"` if a confederate did not interact with the participant.
- The `yawn` variable is either `"yes"` if the participant yawned or `"no"` if the participant did not yawn.

We can use the `janitor` package to get a glimpse into this data in a table format:

```{r}
mythbusters_yawn %>% 
  tabyl(group, yawn) %>% 
  adorn_percentages() %>% 
  adorn_pct_formatting() %>% 
  # To show original counts
  adorn_ns()
```

We are interested in comparing the proportion of those that yawned after seeing a seed versus those that yawned with no seed interaction. We'd like to see if the difference between these two proportions is significantly larger than 0. If so, we'd have evidence to support the claim that yawning is contagious based on this study.

We can make note of some important details in how we're formulating this problem:

- The response variable we are interested in calculating proportions for is `yawn` 
- We are calling a `success` having a `yawn` value of `"yes"`.
- We want to compare the proportion of yesses by `group`.

To summarize, we are looking to see the examine the relationship between yawning and whether or not the participant saw a seed yawn or not.

### Compute the point estimate

```{r error=TRUE}
prop_yes_stats <- mythbusters_yawn %>% 
  group_by(group) %>% 
  summarize(n = n(),
            pi_hat = sum(yawn == "yes")/n,
            var_pi_hat = pi_hat*(1-pi_hat)/n) 
prop_yes_stats
```


```{r}
diff_prop_yes_stats <- prop_yes_stats %>% 
  summarize(diff_in_props = diff(pi_hat),
            SE_diff = sqrt(sum(var_pi_hat))) 

diff_prop_yes_stats
```

This value represents the proportion of those that yawned after seeing a seed yawn (0.2941) minus the proportion of those that yawned with not seeing a seed (0.25).

```{r}
CI <- diff_prop_yes_stats %>% 
  summarize(lower = diff_in_props - 1.96*SE_diff,
            upper = diff_in_props + 1.96*SE_diff)
CI
```

The confidence interval shown here includes the value of 0. We'll see in Chapter \@ref(hypothesis-tests) further what this means in terms of this difference being statistically significant or not, but let's examine a bit here first. The range of plausible values for the difference in the proportion of those that yawned with and without a seed is between `r CI[["lower"]]` and `r CI[["upper"]]`. 

Therefore, we are not sure which proportion is larger. Some of the bootstrap statistics showed the proportion without a seed to be higher and others showed the proportion with a seed to be higher. If the confidence interval was entirely above zero, we would be relatively sure (about "95% confident") that the seed group had a higher proportion of yawning than the control group.

We, therefore, have evidence via this confidence interval suggesting that the conclusion from the Mythbusters show that "yawning is contagious" being "confirmed" is not statistically appropriate.

<!-- nothing in here yet about how sample size affects width of interval. should either include it or have it as an activity for them to explore in class/homework. I also have a shiny app for this https://kgfitz.shinyapps.io/confidence_intervals/ -->
